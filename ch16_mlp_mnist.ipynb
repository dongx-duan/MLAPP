{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "data_path = '/home/hadoop/data/mnist'\n",
    "def load_mnist():\n",
    "    train_data = os.path.join(data_path,'train-images-idx3-ubyte.gz')\n",
    "    train_label = os.path.join(data_path, 'train-labels-idx1-ubyte.gz')\n",
    "    test_data = os.path.join(data_path, 't10k-images-idx3-ubyte.gz')\n",
    "    test_label = os.path.join(data_path, 't10k-labels-idx1-ubyte.gz')\n",
    "    def _read32(bytestream):\n",
    "        return numpy.frombuffer(bytestream.read(4), \n",
    "                        dtype=numpy.dtype(numpy.uint32).newbyteorder('>'))[0]\n",
    "    \n",
    "    def _read_image(filename):\n",
    "        with tf.gfile.Open(filename, 'rb') as f, gzip.GzipFile(fileobj=f) as bytestream:\n",
    "            magic = _read32(bytestream)\n",
    "            if magic != 2051:\n",
    "              raise ValueError(\n",
    "                  'Invalid magic number %d in MNIST image file: %s' %\n",
    "                  (magic, filename))\n",
    "            num_images = _read32(bytestream)\n",
    "            rows = _read32(bytestream)\n",
    "            cols = _read32(bytestream)\n",
    "            buf = bytestream.read(rows * cols * num_images)\n",
    "            data = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "            data = data.reshape(num_images, rows * cols)\n",
    "            return data.astype(numpy.float32)\n",
    "    \n",
    "    def dense_to_one_hot(labels_dense, num_classes):\n",
    "          \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "          num_labels = labels_dense.shape[0]\n",
    "          index_offset = numpy.arange(num_labels) * num_classes\n",
    "          labels_one_hot = numpy.zeros((num_labels, num_classes))\n",
    "          labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "          return labels_one_hot\n",
    "    \n",
    "    def _read_label(filename):\n",
    "        with tf.gfile.Open(filename, 'rb') as f, gzip.GzipFile(fileobj=f) as bytestream:\n",
    "            magic = _read32(bytestream)\n",
    "            if magic != 2049:\n",
    "                ValueError(\n",
    "                  'Invalid magic number %d in MNIST image file: %s' %\n",
    "                  (magic, filename))\n",
    "            num_labels = _read32(bytestream)\n",
    "            buf = bytestream.read(num_labels)\n",
    "            labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "            return dense_to_one_hot(labels.astype(numpy.int32), 10)\n",
    "    \n",
    "    return _read_image(train_data), _read_label(train_label), _read_image(test_data), _read_label(test_label)\n",
    "\n",
    "train_data, train_label, test_data, test_label = load_mnist()\n",
    "\n",
    "assert(train_data.shape == (60000, 784))\n",
    "assert(train_label.shape == (60000, 10))\n",
    "assert(test_data.shape == (10000, 784))\n",
    "assert(test_label.shape == (10000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize image\n",
    "train_data_norm = numpy.expand_dims( numpy.sqrt(numpy.sum(train_data * train_data, axis=1)), axis=1)\n",
    "train_data = numpy.divide(train_data, train_data_norm)\n",
    "\n",
    "test_data_norm = numpy.expand_dims( numpy.sqrt(numpy.sum(test_data * test_data, axis=1)), axis=1)\n",
    "test_data = numpy.divide(test_data, test_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(is_training=True):\n",
    "    def fc(scope, input_size, hidden_size, x):\n",
    "        with tf.variable_scope(scope):\n",
    "            w = tf.get_variable('w', [input_size, hidden_size], \n",
    "                                initializer=tf.random_uniform_initializer(minval=-1.0, maxval=1.0))\n",
    "            b = tf.get_variable('b', [hidden_size], \n",
    "                                initializer=tf.constant_initializer(1))\n",
    "            h = tf.matmul(x,w) + b\n",
    "            if is_training:\n",
    "                h = tf.nn.dropout(h, keep_prob=0.8)\n",
    "            return tf.nn.softmax(h)\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    y = tf.placeholder(tf.float32, [None, 10])\n",
    "    if is_training:\n",
    "        x = tf.nn.dropout(x, keep_prob=0.8)\n",
    "    \n",
    "    z1 = fc('fc1', 784, 128, x)\n",
    "    z2 = fc('fc2', 128, 64, z1)\n",
    "    logits = fc('fc3', 64, 10, z2)\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(logits,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    loss = -tf.reduce_sum(y * tf.log(logits))\n",
    "        \n",
    "    if not is_training:\n",
    "        return x, y, loss, accuracy\n",
    "\n",
    "    lr = 0.005\n",
    "    train_step = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    return x, y, loss, accuracy, train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200\n",
      "train_loss:  33578.043808\n",
      "test_loss:  2734.51   test_accuracy:  0.9381\n",
      "\n",
      "epoch: 400\n",
      "train_loss:  27039.8695831\n",
      "test_loss:  1902.47   test_accuracy:  0.9473\n",
      "\n",
      "epoch: 600\n",
      "train_loss:  24596.6051788\n",
      "test_loss:  1611.39   test_accuracy:  0.9542\n",
      "\n",
      "epoch: 800\n",
      "train_loss:  23444.0808563\n",
      "test_loss:  1472.13   test_accuracy:  0.9583\n",
      "\n",
      "epoch: 1000\n",
      "train_loss:  21871.5790253\n",
      "test_loss:  1392.62   test_accuracy:  0.961\n",
      "\n",
      "epoch: 1200\n",
      "train_loss:  21289.841629\n",
      "test_loss:  1349.07   test_accuracy:  0.9627\n",
      "\n",
      "epoch: 1400\n",
      "train_loss:  20496.9544525\n",
      "test_loss:  1305.26   test_accuracy:  0.9653\n",
      "\n",
      "epoch: 1600\n",
      "train_loss:  19672.5226746\n",
      "test_loss:  1295.08   test_accuracy:  0.9668\n",
      "\n",
      "epoch: 1800\n",
      "train_loss:  19341.6393661\n",
      "test_loss:  1341.24   test_accuracy:  0.9663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    session = tf.Session()\n",
    "    with tf.variable_scope(\"model\", reuse=None):\n",
    "        x_train, y_train, train_loss, train_accuracy, train_step = get_model()\n",
    "    with tf.variable_scope(\"model\", reuse=True):\n",
    "        x_test, y_test, test_loss, test_accuracy = get_model(is_training=False)\n",
    "    \n",
    "    session.run(tf.initialize_all_variables())\n",
    "    batch_size = 512\n",
    "\n",
    "    for i in range(1, 2000):\n",
    "        perm = numpy.random.permutation(numpy.arange(len(train_data)))\n",
    "        _train = train_data[perm]\n",
    "        _label = train_label[perm]\n",
    "        \n",
    "        _train_loss = 0\n",
    "        for k in range(len(train_data)/batch_size - 1):\n",
    "            start = k * batch_size\n",
    "            end = (k+1) * batch_size\n",
    "            _loss, _ = session.run([train_loss, train_step], \n",
    "                                   feed_dict={x_train:_train[start:end], y_train:_label[start:end]})\n",
    "            _train_loss += _loss\n",
    "    \n",
    "        if i % 200 == 0:\n",
    "            print \"epoch:\", i\n",
    "            print \"train_loss: \", _train_loss\n",
    "            _test_loss, _test_accuracy = session.run([test_loss, test_accuracy], \n",
    "                                                     feed_dict={x_test:test_data, y_test:test_label})\n",
    "            print \"test_loss: \", _test_loss, \"  test_accuracy: \", _test_accuracy\n",
    "            print \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
