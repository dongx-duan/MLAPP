{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "data_path = '/home/hadoop/data/mnist'\n",
    "def load_mnist():\n",
    "    train_data = os.path.join(data_path,'train-images-idx3-ubyte.gz')\n",
    "    train_label = os.path.join(data_path, 'train-labels-idx1-ubyte.gz')\n",
    "    test_data = os.path.join(data_path, 't10k-images-idx3-ubyte.gz')\n",
    "    test_label = os.path.join(data_path, 't10k-labels-idx1-ubyte.gz')\n",
    "    def _read32(bytestream):\n",
    "        return numpy.frombuffer(bytestream.read(4), \n",
    "                        dtype=numpy.dtype(numpy.uint32).newbyteorder('>'))[0]\n",
    "    \n",
    "    def _read_image(filename):\n",
    "        with tf.gfile.Open(filename, 'rb') as f, gzip.GzipFile(fileobj=f) as bytestream:\n",
    "            magic = _read32(bytestream)\n",
    "            if magic != 2051:\n",
    "              raise ValueError(\n",
    "                  'Invalid magic number %d in MNIST image file: %s' %\n",
    "                  (magic, filename))\n",
    "            num_images = _read32(bytestream)\n",
    "            rows = _read32(bytestream)\n",
    "            cols = _read32(bytestream)\n",
    "            buf = bytestream.read(rows * cols * num_images)\n",
    "            data = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "            data = data.reshape(num_images, rows * cols)\n",
    "            return data.astype(numpy.float32)\n",
    "    \n",
    "    def dense_to_one_hot(labels_dense, num_classes):\n",
    "          \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "          num_labels = labels_dense.shape[0]\n",
    "          index_offset = numpy.arange(num_labels) * num_classes\n",
    "          labels_one_hot = numpy.zeros((num_labels, num_classes))\n",
    "          labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "          return labels_one_hot\n",
    "    \n",
    "    def _read_label(filename):\n",
    "        with tf.gfile.Open(filename, 'rb') as f, gzip.GzipFile(fileobj=f) as bytestream:\n",
    "            magic = _read32(bytestream)\n",
    "            if magic != 2049:\n",
    "                ValueError(\n",
    "                  'Invalid magic number %d in MNIST image file: %s' %\n",
    "                  (magic, filename))\n",
    "            num_labels = _read32(bytestream)\n",
    "            buf = bytestream.read(num_labels)\n",
    "            labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "            return dense_to_one_hot(labels.astype(numpy.int32), 10)\n",
    "    \n",
    "    return _read_image(train_data), _read_label(train_label), _read_image(test_data), _read_label(test_label)\n",
    "\n",
    "train_data, train_label, test_data, test_label = load_mnist()\n",
    "\n",
    "assert(train_data.shape == (60000, 784))\n",
    "assert(train_label.shape == (60000, 10))\n",
    "assert(test_data.shape == (10000, 784))\n",
    "assert(test_label.shape == (10000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize image\n",
    "train_data_norm = numpy.expand_dims( numpy.sqrt(numpy.sum(train_data * train_data, axis=1)), axis=1)\n",
    "train_data = numpy.divide(train_data, train_data_norm)\n",
    "\n",
    "test_data_norm = numpy.expand_dims( numpy.sqrt(numpy.sum(test_data * test_data, axis=1)), axis=1)\n",
    "test_data = numpy.divide(test_data, test_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model(is_training=True):\n",
    "    # helper function of full connection layer\n",
    "    def fc(scope, input_size, output_size, x, keep_prob=0.8):\n",
    "        with tf.variable_scope(scope):\n",
    "            if is_training:\n",
    "                x = tf.nn.dropout(x, keep_prob)\n",
    "            \n",
    "            w = tf.get_variable('w', [input_size, output_size], \n",
    "                                initializer=tf.random_uniform_initializer(minval=-1.0, maxval=1.0))\n",
    "            b = tf.get_variable('b', [output_size], \n",
    "                                initializer=tf.constant_initializer(1))\n",
    "            return tf.matmul(x,w) + b\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    y = tf.placeholder(tf.float32, [None, 10])\n",
    "    \n",
    "    z1 = tf.nn.sigmoid(fc('fc1', 784, 128, x))\n",
    "    z2 = tf.nn.sigmoid(fc('fc2', 128, 64, z1))\n",
    "    logits = tf.nn.softmax(fc('fc3', 64, 10, z2))\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(logits,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    loss = -tf.reduce_mean(y * tf.log(logits))\n",
    "    \n",
    "    if not is_training:\n",
    "        return x, y, loss, accuracy\n",
    "\n",
    "    lr = 0.5\n",
    "    train_step = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    return x, y, loss, accuracy, train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1000\n",
      "train_loss:  0.0306265090656\n",
      "test_loss:  0.0166162   test_accuracy:  0.9497\n",
      "\n",
      "epoch: 2000\n",
      "train_loss:  0.0231371994476\n",
      "test_loss:  0.0124095   test_accuracy:  0.9615\n",
      "\n",
      "epoch: 3000\n",
      "train_loss:  0.0195585493448\n",
      "test_loss:  0.0105967   test_accuracy:  0.9667\n",
      "\n",
      "epoch: 4000\n",
      "train_loss:  0.0177569502788\n",
      "test_loss:  0.00948308   test_accuracy:  0.9709\n",
      "\n",
      "epoch: 5000\n",
      "train_loss:  0.0159739239446\n",
      "test_loss:  0.00873825   test_accuracy:  0.9728\n",
      "\n",
      "epoch: 6000\n",
      "train_loss:  0.0148734457847\n",
      "test_loss:  0.00814674   test_accuracy:  0.9743\n",
      "\n",
      "epoch: 7000\n",
      "train_loss:  0.0140023315707\n",
      "test_loss:  0.00774166   test_accuracy:  0.975\n",
      "\n",
      "epoch: 8000\n",
      "train_loss:  0.01308704671\n",
      "test_loss:  0.00738087   test_accuracy:  0.9762\n",
      "\n",
      "epoch: 9000\n",
      "train_loss:  0.0125466258855\n",
      "test_loss:  0.0071132   test_accuracy:  0.9771\n",
      "\n",
      "epoch: 10000\n",
      "train_loss:  0.0119407029927\n",
      "test_loss:  0.00687556   test_accuracy:  0.9777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    session = tf.Session()\n",
    "    with tf.variable_scope(\"model\", reuse=None):\n",
    "        x_train, y_train, train_loss, train_accuracy, train_step = get_model()\n",
    "    with tf.variable_scope(\"model\", reuse=True):\n",
    "        x_test, y_test, test_loss, test_accuracy = get_model(is_training=False)\n",
    "    \n",
    "    session.run(tf.initialize_all_variables())\n",
    "    batch_size = 256\n",
    "\n",
    "    for i in range(1, 10001):\n",
    "        perm = numpy.random.permutation(numpy.arange(len(train_data)))\n",
    "        _train = train_data[perm]\n",
    "        _label = train_label[perm]\n",
    "        \n",
    "        _train_loss = 0\n",
    "        for k in range(len(train_data)/batch_size - 1):\n",
    "            start = k * batch_size\n",
    "            end = (k+1) * batch_size\n",
    "            _loss, _ = session.run([train_loss, train_step], \n",
    "                                   feed_dict={x_train:_train[start:end], y_train:_label[start:end]})\n",
    "            _train_loss += _loss\n",
    "    \n",
    "        if i % 1000 == 0:\n",
    "            print \"epoch:\", i\n",
    "            print \"train_loss: \", _train_loss/k\n",
    "            _test_loss, _test_accuracy = session.run([test_loss, test_accuracy], \n",
    "                                                     feed_dict={x_test:test_data, y_test:test_label})\n",
    "            print \"test_loss: \", _test_loss, \"  test_accuracy: \", _test_accuracy\n",
    "            print \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
